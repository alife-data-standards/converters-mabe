import json
import csv
import os

import argparse
parser = argparse.ArgumentParser(description='Converts .csv files generated by MABE to ALDS...')
parser.add_argument('-path', type=str, metavar='PATH', default = '',  help='path to files - default : none (will read files in current directory)', required=False)
parser.add_argument('-fileType', type=str, metavar='TYPE', default = 'snapshot',  help='type of file, either snapshot or SSwD, default : snapshot', required=False)
parser.add_argument('-oldColumnNames', type=str, metavar='COLUMN_NAME', default = ['score_AVE'],  help='column names of data to read from source files - default : "score_AVE" ("ID", "timeOfBirth", and the correct ancestors list are added to the list automatically)',nargs='+', required=False)
parser.add_argument('-newColumnNames', type=str, metavar='COLUMN_NAME', default = [],  help='column names of data to be copied into new data file - default : NONE, if blank, copy oldColumnNames ("id", "origin_time", and "parents" are added to the list automatically)',nargs='+', required=False)
parser.add_argument('-updateRange', type=int, metavar=('FIRST','LAST','STEP'),  help='update range of files to convert (from first to last on step)', nargs=3, required=True)
parser.add_argument('-verbose', action='store_true', default = False, help='adding -verbose will provide more text output while running (useful if you are working with a lot of data to make sure that you are not hanging) - default (if not set) : OFF', required=False)

args = parser.parse_args()

if args.fileType == "SSwD":
    ancestorsColumnName = 'ancestors_LIST'
    filePrefix = 'SSwD_data_'
else:
    ancestorsColumnName = 'snapshotAncestors_LIST'
    filePrefix = 'snapshot_data_'

	
ofInterest = []
ofInterest.append('ID')
ofInterest.append(ancestorsColumnName)
ofInterest.append('timeOfBirth')
ofInterest = ofInterest + args.oldColumnNames  # find these columns

ofInterestRenames = []
ofInterestRenames.append('id')
ofInterestRenames.append('ancestor_list')
ofInterestRenames.append('origin_time')
if args.newColumnNames == []:
    ofInterestRenames = ofInterestRenames + args.oldColumnNames # save them with these new column names
else:
    if len(args.oldColumnNames) != len(args.newColumnNames):
        print('\nERROR:\n   "oldColumnNames" and "newColumnNames" have different numbers of elements, please correct and try again.')
        exit()
    ofInterestRenames = ofInterestRenames + args.newColumnNames # save them with these new column names

filePath = args.path
rawData = {}

mustGetHeader = True
for t in range(args.updateRange[0],args.updateRange[1]+1,args.updateRange[2]):
    fileName = filePath + filePrefix + str(t) + '.csv'
    with open(fileName, 'r') as csvfile:
        if(args.verbose):
            print('loading',fileName)

        data = csv.reader(csvfile, delimiter=',', quotechar='"')
        firstLineInFile = True
        for line in data:
            if firstLineInFile: # first line of file, do not recored to raw data
                firstLineInFile = False
                if mustGetHeader: # first line, of first file; keep it as header
                    origColumnNames = line
                    mustGetHeader = False
                    # get index of ID
                    IDIndex = line.index('ID')
            else:
                rawData[line[IDIndex]] = line # if same ID appears more then once, save the last appearance

                
ofInterestIndices = [origColumnNames.index(colName) for colName in ofInterest]

#construct a data object we can serialize
outData = {}

for orgID in rawData:
    dataOnThisLine = {}
    for colIndex,colName,colNameOld in zip(ofInterestIndices,ofInterestRenames,ofInterest):
        #if rawData[orgID][colIndex][0] == '[':
        if colNameOld[-5:] == '_LIST':
            #print(colNameOld,rawData[orgID][colIndex])
            #print(colNameOld,rawData[orgID])
            if (rawData[orgID][colIndex][-1] == ','):
                rawData[orgID][colIndex] = rawData[orgID][colIndex][:-1]
            dataOnThisLine[colName]=[int(s) for s in rawData[orgID][colIndex].split(',')]
        else:
            dataOnThisLine[colName]=rawData[orgID][colIndex]
    outData[orgID] = dataOnThisLine

csv_file = "lineage.csv"

print('saving',csv_file)
with open(csv_file, 'w') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=ofInterestRenames, lineterminator="\n")
    writer.writeheader()
    for orgID in rawData:
        writer.writerow(outData[orgID])

json_file = 'lineage.json'
print('saving',json_file)

with open(json_file, 'w') as fp:
    json.dump(outData, fp, sort_keys=True, indent=4)
    